# Music Assistant v3 - 개선 개발 계획서

서버 안정성(500 오류) 및 온셋 탐지 정확도 문제를 해결하고, 최종적으로 악보 생성을 목표로 하는 멜로디 분석 시스템 고도화 프로젝트입니다.

## 프로젝트 개요

각 단계(Phase)는 독립적이고 완전한 실행 가능한 결과물을 목표로 하며, 모든 신규 백엔드 작업은 **`backend_v3`** 디렉토리에서 진행됩니다.

---

## Phase 1: 비동기 아키텍처 기반 구축 (서버 안정성 확보)

**목표**: 긴 오디오 파일 분석 시 발생하는 `500 Internal Server Error`를 근본적으로 해결하기 위해, 비동기 처리 방식의 안정적인 백엔드 아키텍처를 구축합니다.

### 백엔드 (`backend_v3`)

#### 신규 작업 환경 구성

- [x] 기존 `backend`, `backend_v2`에 영향을 주지 않도록 `backend_v3` 디렉토리 생성

#### 기술 스택 선정 및 설정

- [x] 고성능 웹 프레임워크 **FastAPI** 도입
- [x] 비동기 작업 처리를 위한 **Celery**와 메시지 브로커 **Redis** 환경 설정

#### 비동기 API 엔드포인트 설계

- [x] `POST /api/v3/analysis`: 오디오 파일을 받아 분석 작업을 Celery 큐에 등록하고, 즉시 `task_id`를 반환
- [x] `GET /api/v3/analysis/{task_id}`: `task_id`를 사용하여 작업 상태(대기, 진행 중, 성공, 실패)를 조회(Polling)

#### 기본 분석 작업 구현

- [x] Celery 워커에서 실행될 기본 오디오 분석 작업(음고, 온셋) 구현
- [x] 분석 완료 시 결과를 Redis 결과 백엔드에 저장

### 실행 및 테스트

- [x] `backend_v3`의 FastAPI 서버와 Celery 워커를 각각 실행
- [x] Postman 등을 사용하여 긴 오디오 파일을 업로드해도 `500 오류` 없이 `task_id`가 즉시 반환되는지 확인
- [x] 폴링(Polling) 엔드포인트를 통해 작업 상태가 정상적으로 조회되는지 확인

### 결과물

- [x] 대용량 오디오 파일도 안정적으로 처리할 수 있는 비동기 방식의 `backend_v3` API 서버

---

## Phase 2: 고급 온셋 탐지 및 민감도 조절 기능 구현

**목표**: 온셋 과탐지 문제를 해결하고, 사용자가 분석의 민감도를 직접 제어할 수 있는 유연한 분석 엔진을 구현합니다.

### 백엔드 (`backend_v3`)

#### 핵심 로직 개선

- [x] Celery 작업 내 온셋 탐지 로직을 `librosa.onset.onset_strength`와 `librosa.util.peak_pick` 조합으로 교체
- [x] 스펙트럼 변화(Spectral Flux) 기반의 알고리즘을 통해 음악적으로 더 의미 있는 온셋 추출

#### API 엔드포인트 확장

- [x] `POST /api/v3/analysis` 엔드포인트가 온셋 탐지 민감도를 조절할 수 있는 선택적 JSON 파라미터(예: `delta`, `wait`)를 받도록 수정
- [x] FastAPI의 Pydantic 모델을 사용하여 파라미터 유효성 검사 구현

#### 동적 파라미터 적용

- [x] 사용자가 전달한 `delta`, `wait` 값을 Celery 작업으로 넘겨 `librosa.util.peak_pick` 함수에 동적으로 적용

### 실행 및 테스트

- [x] 동일한 오디오 파일에 대해 `delta` 값을 다르게 설정하여 API를 호출하고, 온셋 탐지 결과 개수가 의도대로 변경되는지 확인
- [x] 이전 버전(`backend_v2`)의 결과와 비교하여 과탐지 문제가 현저히 개선되었는지 검증

### 결과물

- [x] 정확도가 향상되고, 사용자가 API를 통해 민감도를 직접 제어할 수 있는 고도화된 온셋 분석 엔진

---

## Phase 3: 프론트엔드 시각화를 위한 데이터 제공

**목표**: 프론트엔드에서 파형, 스펙트로그램, 음고, 온셋 등을 포함한 종합적인 분석 차트를 렌더링하는 데 필요한 모든 데이터를 구조화된 단일 JSON 객체로 제공합니다.

### 백엔드 (`backend_v3`)

#### 최종 출력 JSON 구조 설계

- [x] `GET /api/v3/analysis/{task_id}`가 작업 성공 시 반환할 최종 JSON 데이터 구조 정의
- [x] 포함될 데이터:
  - [x] **파형 데이터**: 시각화에 적합하도록 다운샘플링된 진폭 값 배열
  - [x] **음고 윤곽선**: `[시간(초), 주파수(Hz)]` 쌍으로 구성된 배열 (음고 없는 구간은 `null` 처리)
  - [x] **온셋 마커**: 최종 탐지된 온셋의 시간(초) 값 배열
  - [x] **분석 메타데이터**: 분석에 사용된 `delta` 등 주요 파라미터 값

#### 데이터 가공 로직 구현

- [x] Celery 작업 내에서 분석 완료 후, 위 설계에 맞춰 데이터를 가공하고 최종 JSON 객체를 생성하는 로직 추가

### 프론트엔드 (Next.js) - 연동 가이드

- [x] Chart.js와 같은 라이브러리에서 해당 JSON 데이터를 사용하는 방법 가이드 제공
- [x] 민감도 조절 슬라이더 UI 구현 시, 불필요한 API 호출을 막기 위한 **디바운싱(Debouncing)** 적용 권고

### 실행 및 테스트

- [x] 분석 성공 후 반환되는 JSON 객체가 설계된 구조와 모든 필수 데이터를 포함하는지 확인
- [x] 프론트엔드에서 해당 데이터로 차트를 그리는 데 문제가 없는지 검증

### 결과물

- [x] 프론트엔드 시각화에 최적화된, 풍부하고 구조화된 JSON 데이터 제공 기능

---

## Phase 4: 음악 악보 생성 기능 (확장)

**목표**: 분석된 멜로디 데이터를 표준 악보 형식인 MusicXML로 변환하여, 사용자가 자신의 연주를 악보로 확인할 수 있는 부가 가치를 제공합니다.

### 백엔드 (`backend_v3`)

#### 템포 및 리듬 분석 추가

- [ ] 인간 연주의 표현적인 속도 변화(루바토)를 고려하기 위해 `librosa.beat.beat_track`을 사용한 동적 템포 추적 기능 추가

#### 악보 변환 로직 구현

- [ ] 악보 생성을 위한 **`music21`** 라이브러리 통합
- [ ] 탐지된 음표 정보(음고, 시작 시간, 지속 시간)를 `music21` 객체로 변환하는 로직 구현
- [ ] 동적 템포 정보를 사용하여 물리적 시간(초)을 음악적 박자(`quarterLength`)로 변환

#### 신규 API 엔드포인트 설계

- [ ] `GET /api/v3/analysis/{task_id}/musicxml`: 분석이 완료된 작업에 대해 MusicXML 형식의 악보 데이터를 문자열로 반환하는 엔드포인트 생성

### 프론트엔드 (Next.js) - 연동 가이드

- [ ] **OpenSheetMusicDisplay (OSMD)** 와 같은 라이브러리를 사용하여 브라우저에서 MusicXML을 직접 렌더링하는 방법 가이드 제공

### 실행 및 테스트

- [ ] 생성된 MusicXML 파일을 MuseScore나 OSMD 뷰어에서 열었을 때, 원본 멜로디와 유사한 악보가 정상적으로 표시되는지 확인
- [ ] 템포가 변하는 곡에 대해 리듬이 정확하게 표기되는지 검증

### 결과물

- [ ] 분석된 멜로디의 MusicXML 악보 데이터를 제공하는 API 엔드포인트 및 기능
